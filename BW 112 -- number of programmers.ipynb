{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ace19e3-9325-46bb-aae7-7f9402c0b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = '/Users/reuven/BambooWeekly/notebooks/data/all_data_M_2023.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33095fba-129e-4fb4-830d-1d118d557dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read in the data from Excel. We only need some of the columns (AREA_TITLE, AREA_TYPE, OCC_TITLE, I_GROUP, TOT_EMP, JOBS_1000, \n",
    "# O_GROUP, PCT_TOTAL, and A_MEAN. Treat \"*\", \"**\", and \"#\" as a `NaN` value. Does it take less time to read the data if we limit the columns? How much does it change the size of the data (in memory) by limiting the columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87b240ff-de46-4612-b501-a21ab8872704",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(filename,\n",
    "                   na_values=['*', '**', '#'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15ed2ce3-3ec6-48ed-ba4b-83d5ed477b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(413327, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b94e9651-cfca-4618-a907-b410d94e13b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(317796833)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.memory_usage(deep=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "085a7e99-9179-4812-aa03-f8d792d8e6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(filename,\n",
    "                   na_values=['*', '**', '#'],\n",
    "                  usecols=['AREA_TITLE', 'AREA_TYPE', 'OCC_TITLE', 'I_GROUP',\n",
    "                           'TOT_EMP', 'JOBS_1000', 'O_GROUP', 'PCT_TOTAL', 'A_MEAN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f2eaa40-3e02-4352-a6fb-0df49ec49cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(126157950)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.memory_usage(deep=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71290173-65c7-4cfc-8052-49432186df73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3969767376504976"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "126157950 / 317796833"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd2c6f02-5262-47e4-bdac-fb40daf1503d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.9 ms ± 543 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# 2. Store the data in Feather and Parquet format, and read from these files back into Pandas. Does it take less time \n",
    "# to read from these formats? Which is faster?\n",
    "\n",
    "%timeit df.to_feather('/tmp/mydata.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c483a1fd-21fe-494f-9093-ed118c15a980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 ms ± 3.72 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit df.to_parquet('/tmp/mydata.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0651f1c2-9b92-4356-81bd-47c845dccbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 reuven wheel  13M Apr  3 15:33 /tmp/mydata.feather\n",
      "-rw-r--r-- 1 reuven wheel 2.8M Apr  3 15:33 /tmp/mydata.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -lh /tmp/mydata.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7009b62-9145-4f39-a66b-a4831c85f23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.2 ms ± 238 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pd.read_feather('/tmp/mydata.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4c42645-4474-4c0c-a918-14d5e6a04ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.6 ms ± 743 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pd.read_parquet('/tmp/mydata.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c11257-277c-4954-b309-f6b00cf7e0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
